{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfaa505b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask_weared_incorrect 0\n",
      "with_mask 1\n",
      "without_mask 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0] global /tmp/pip-req-build-xw6jtoah/opencv_contrib/modules/xfeatures2d/misc/python/shadow_sift.hpp (13) SIFT_create DEPRECATED: cv.xfeatures2d.SIFT_create() is deprecated due SIFT tranfer to the main repository. https://github.com/opencv/opencv/issues/16736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy =  0.43\n",
      "\n",
      "recall =  0.43\n",
      "\n",
      "precision =  0.43\n",
      "\n",
      "[[mask_weared_incorrect      -             -      ]\n",
      " [         -             with_mask         -      ]\n",
      " [         -                 -       without_mask ]]\n",
      "\n",
      "[[79 21  0]\n",
      " [50 50  0]\n",
      " [52 48  0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pylab as pl\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score #sreeni\n",
    "import joblib\n",
    "\n",
    "\n",
    "# Load the classifier, class names, scaler, number of clusters and vocabulary \n",
    "#from stored pickle file (generated during training)\n",
    "clf, classes_names, stdSlr, k, voc = joblib.load(\"bovw.pkl\")\n",
    "\n",
    "# Get the path of the testing image(s) and store them in a list\n",
    "test_path = 'Tensorflow/workspace/images/test_bovw'\n",
    "\n",
    "testing_names = os.listdir(test_path)\n",
    "testing_names.sort() #['mask_weared_incorrect', 'with_mask', 'without_mask']\n",
    "\n",
    "# Get path to all images and save them in a list\n",
    "# image_paths and the corresponding label in image_paths\n",
    "image_paths = []\n",
    "image_classes = []\n",
    "class_id = 0\n",
    "\n",
    "#To make it easy to list all file names in a directory let us define a function\n",
    "#\n",
    "def imglist(path):\n",
    "    return [os.path.join(path, f) for f in os.listdir(path)]\n",
    "\n",
    "#Fill the placeholder empty lists with image path, classes, and add class ID number\n",
    "\n",
    "for testing_name in testing_names:\n",
    "    dir = os.path.join(test_path, testing_name)\n",
    "    image_list = imglist(dir)\n",
    "    image_paths+=image_list\n",
    "    image_classes+=[class_id]*len(image_list)\n",
    "    print(testing_name, end=\" \")\n",
    "    print(class_id)\n",
    "    class_id+=1\n",
    "    \n",
    "# Create feature extraction and keypoint detector objects\n",
    "# Create List where all the descriptors will be stored\n",
    "des_list = []\n",
    "\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "for image_path in image_paths:\n",
    "    im = cv2.imread(image_path)\n",
    "    kpts, des = sift.detectAndCompute(im, None)\n",
    "    des_list.append((image_path, des))   \n",
    "    \n",
    "# Stack all the descriptors vertically in a numpy array\n",
    "descriptors = des_list[0][1]\n",
    "for image_path, descriptor in des_list[0:]:\n",
    "    descriptors = np.vstack((descriptors, descriptor)) \n",
    "\n",
    "# Calculate the histogram of features\n",
    "#vq Assigns codes from a code book to observations.\n",
    "from scipy.cluster.vq import vq    \n",
    "test_features = np.zeros((len(image_paths), k), \"float32\")\n",
    "for i in range(len(image_paths)):\n",
    "    words, distance = vq(des_list[i][1],voc)\n",
    "    for w in words:\n",
    "        test_features[i][w] += 1\n",
    "\n",
    "# Perform Tf-Idf vectorization\n",
    "nbr_occurences = np.sum( (test_features > 0) * 1, axis = 0)\n",
    "idf = np.array(np.log((1.0*len(image_paths)+1) / (1.0*nbr_occurences + 1)), 'float32')\n",
    "\n",
    "# Scale the features\n",
    "#Standardize features by removing the mean and scaling to unit variance\n",
    "#Scaler (stdSlr comes from the pickled file we imported)\n",
    "test_features = stdSlr.transform(test_features)\n",
    "\n",
    "#######Until here most of the above code is similar to Train except for kmeans clustering####\n",
    "\n",
    "#Report true class names so they can be compared with predicted classes\n",
    "true_class =  [classes_names[i] for i in image_classes]\n",
    "# Perform the predictions and report predicted class names. \n",
    "predictions =  [classes_names[i] for i in clf.predict(test_features)]\n",
    "\n",
    "\n",
    "###############################################\n",
    "#To make it easy to understand the accuracy let us print the confusion matrix\n",
    "\n",
    "def showconfusionmatrix(cm):\n",
    "    pl.matshow(cm)\n",
    "    pl.title('Confusion matrix')\n",
    "    pl.colorbar()\n",
    "    pl.show()\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(true_class, predictions)\n",
    "recall = recall_score(true_class, predictions, average='micro')\n",
    "precision = precision_score(true_class, predictions, average='micro')\n",
    "print (\"accuracy = \", accuracy)\n",
    "print()\n",
    "print(\"recall = \", recall)\n",
    "print()\n",
    "print(\"precision = \", precision)\n",
    "print()\n",
    "print(\"[[mask_weared_incorrect      -             -      ]\")\n",
    "print(\" [         -             with_mask         -      ]\")\n",
    "print(\" [         -                 -       without_mask ]]\")\n",
    "print()\n",
    "cm = confusion_matrix(true_class, predictions)\n",
    "print (cm)\n",
    "\n",
    "showconfusionmatrix(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72d1e53f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trying loading the pipeline.config...\t[LOADED]\n",
      "\n",
      "Trying restoring the checkpoint...\t[RESTORED]\n",
      "\n",
      "Trying loading the label_map...\t[LOADED]\n",
      "\n",
      "accuracy =  0.9133333333333333\n",
      "\n",
      "recall =  0.9133333333333333\n",
      "\n",
      "precision =  0.9133333333333333\n",
      "\n",
      "[[mask_weared_incorrect      -             -      ]\n",
      " [         -             with_mask         -      ]\n",
      " [         -                 -       without_mask ]]\n",
      "\n",
      "[[90 10  0]\n",
      " [ 6 91  3]\n",
      " [ 3  4 93]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'    # Suppress TensorFlow logging\n",
    "\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # Suppress Matplotlib warnings\n",
    "\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')           # Suppress TensorFlow logging (2)\n",
    "\n",
    "CUSTOM_MODEL_NAME = 'my_ssd_mobilnet'\n",
    "LABEL_MAP_NAME = 'label_map.pbtxt'\n",
    "\n",
    "paths = {\n",
    "    'ANNOTATION_PATH': os.path.join('Tensorflow', 'workspace','annotations'),\n",
    "    'CHECKPOINT_PATH': os.path.join('Tensorflow', 'workspace','exported-models', 'my_model', 'checkpoint')\n",
    " }\n",
    "\n",
    "files = {\n",
    "    'PIPELINE_CONFIG':os.path.join('Tensorflow', 'workspace','models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
    "    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n",
    "    }\n",
    "\n",
    "print()\n",
    "# %%\n",
    "# Load pipeline config and build a detection model\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "print(\"Trying loading the pipeline.config...\", end='\\t')\n",
    "configs = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\n",
    "model_config = configs['model']\n",
    "detection_model = model_builder.build(model_config=model_config, is_training=False)\n",
    "print(\"[LOADED]\")\n",
    "print()\n",
    "\n",
    "# %%\n",
    "# Restore checkpoint\n",
    "# ~~~~~~~~~~~~~~~~~~~~\n",
    "print(\"Trying restoring the checkpoint...\", end='\\t')\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(os.path.join(paths['CHECKPOINT_PATH'], 'ckpt-0')).expect_partial()\n",
    "print(\"[RESTORED]\")\n",
    "print()\n",
    "\n",
    "@tf.function\n",
    "def detect_fn(image):\n",
    "    \"\"\"Detect objects in image.\"\"\"\n",
    "\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "\n",
    "    return detections\n",
    "\n",
    "\n",
    "# %%\n",
    "# Load label map data (for plotting)\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "print(\"Trying loading the label_map...\", end='\\t')\n",
    "category_index = label_map_util.create_category_index_from_labelmap(files['LABELMAP'], use_display_name=True)\n",
    "print(\"[LOADED]\")\n",
    "print()\n",
    "\n",
    "\n",
    "def load_image_into_numpy_array(path):\n",
    "    return np.array(Image.open(path))\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for image_path in image_paths:\n",
    "    \n",
    "    image_np = load_image_into_numpy_array(image_path)\n",
    "\n",
    "    # Things to try:\n",
    "    # Flip horizontally\n",
    "    # image_np = np.fliplr(image_np).copy()\n",
    "\n",
    "    # Convert image to grayscale\n",
    "    # image_np = np.tile(\n",
    "    #     np.mean(image_np, 2, keepdims=True), (1, 1, 3)).astype(np.uint8)\n",
    "\n",
    "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "    \n",
    "    detections = detect_fn(input_tensor)\n",
    "\n",
    "    # All outputs are batches tensors.\n",
    "    # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
    "    # We're only interested in the first num_detections.\n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy()\n",
    "                  for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "\n",
    "    # detection_classes should be ints.\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "    label_id_offset = 1\n",
    "    \n",
    "    #return the class with the most probability\n",
    "    class_id = int(detections['detection_classes'][0] + label_id_offset)\n",
    "            \n",
    "    predictions.append(category_index[class_id][\"name\"])\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(true_class, predictions)\n",
    "recall = recall_score(true_class, predictions, average='micro')\n",
    "precision = precision_score(true_class, predictions, average='micro')\n",
    "print (\"accuracy = \", accuracy)\n",
    "print()\n",
    "print(\"recall = \", recall)\n",
    "print()\n",
    "print(\"precision = \", precision)\n",
    "print()\n",
    "print(\"[[mask_weared_incorrect      -             -      ]\")\n",
    "print(\" [         -             with_mask         -      ]\")\n",
    "print(\" [         -                 -       without_mask ]]\")\n",
    "print()\n",
    "cm = confusion_matrix(true_class, predictions)\n",
    "print (cm)\n",
    "\n",
    "showconfusionmatrix(cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
