{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfaa505b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask_weared_incorrect 0\n",
      "with_mask 1\n",
      "without_mask 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0] global /tmp/pip-req-build-xw6jtoah/opencv_contrib/modules/xfeatures2d/misc/python/shadow_sift.hpp (13) SIFT_create DEPRECATED: cv.xfeatures2d.SIFT_create() is deprecated due SIFT tranfer to the main repository. https://github.com/opencv/opencv/issues/16736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy =  0.43478260869565216\n",
      "\n",
      "recall =  0.43478260869565216\n",
      "\n",
      "precision =  0.43478260869565216\n",
      "\n",
      "[[mask_weared_incorrect      -             -      ]\n",
      " [         -             with_mask         -      ]\n",
      " [         -                 -       without_mask ]]\n",
      "\n",
      "[[54 17  0]\n",
      " [24 16  0]\n",
      " [15 35  0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pylab as pl\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score #sreeni\n",
    "import joblib\n",
    "\n",
    "\n",
    "# Load the classifier, class names, scaler, number of clusters and vocabulary \n",
    "#from stored pickle file (generated during training)\n",
    "clf, classes_names, stdSlr, k, voc = joblib.load(\"bovw.pkl\")\n",
    "\n",
    "# Get the path of the testing image(s) and store them in a list\n",
    "test_path = 'Tensorflow/workspace/images/test_bovw'\n",
    "\n",
    "testing_names = os.listdir(test_path)\n",
    "testing_names.sort() #['mask_weared_incorrect', 'with_mask', 'without_mask']\n",
    "\n",
    "# Get path to all images and save them in a list\n",
    "# image_paths and the corresponding label in image_paths\n",
    "image_paths = []\n",
    "image_classes = []\n",
    "class_id = 0\n",
    "\n",
    "#To make it easy to list all file names in a directory let us define a function\n",
    "#\n",
    "def imglist(path):\n",
    "    return [os.path.join(path, f) for f in os.listdir(path)]\n",
    "\n",
    "#Fill the placeholder empty lists with image path, classes, and add class ID number\n",
    "\n",
    "for testing_name in testing_names:\n",
    "    dir = os.path.join(test_path, testing_name)\n",
    "    image_list = imglist(dir)\n",
    "    image_paths+=image_list\n",
    "    image_classes+=[class_id]*len(image_list)\n",
    "    print(testing_name, end=\" \")\n",
    "    print(class_id)\n",
    "    class_id+=1\n",
    "    \n",
    "# Create feature extraction and keypoint detector objects\n",
    "# Create List where all the descriptors will be stored\n",
    "des_list = []\n",
    "\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "for image_path in image_paths:\n",
    "    im = cv2.imread(image_path)\n",
    "    kpts, des = sift.detectAndCompute(im, None)\n",
    "    des_list.append((image_path, des))   \n",
    "    \n",
    "# Stack all the descriptors vertically in a numpy array\n",
    "descriptors = des_list[0][1]\n",
    "for image_path, descriptor in des_list[0:]:\n",
    "    descriptors = np.vstack((descriptors, descriptor)) \n",
    "\n",
    "# Calculate the histogram of features\n",
    "#vq Assigns codes from a code book to observations.\n",
    "from scipy.cluster.vq import vq    \n",
    "test_features = np.zeros((len(image_paths), k), \"float32\")\n",
    "for i in range(len(image_paths)):\n",
    "    words, distance = vq(des_list[i][1],voc)\n",
    "    for w in words:\n",
    "        test_features[i][w] += 1\n",
    "\n",
    "# Perform Tf-Idf vectorization\n",
    "nbr_occurences = np.sum( (test_features > 0) * 1, axis = 0)\n",
    "idf = np.array(np.log((1.0*len(image_paths)+1) / (1.0*nbr_occurences + 1)), 'float32')\n",
    "\n",
    "# Scale the features\n",
    "#Standardize features by removing the mean and scaling to unit variance\n",
    "#Scaler (stdSlr comes from the pickled file we imported)\n",
    "test_features = stdSlr.transform(test_features)\n",
    "\n",
    "#######Until here most of the above code is similar to Train except for kmeans clustering####\n",
    "\n",
    "#Report true class names so they can be compared with predicted classes\n",
    "true_class =  [classes_names[i] for i in image_classes]\n",
    "# Perform the predictions and report predicted class names. \n",
    "predictions =  [classes_names[i] for i in clf.predict(test_features)]\n",
    "\n",
    "\n",
    "###############################################\n",
    "#To make it easy to understand the accuracy let us print the confusion matrix\n",
    "\n",
    "def showconfusionmatrix(cm):\n",
    "    pl.matshow(cm)\n",
    "    pl.title('Confusion matrix')\n",
    "    pl.colorbar()\n",
    "    pl.show()\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(true_class, predictions)\n",
    "recall = recall_score(true_class, predictions, average='micro')\n",
    "precision = precision_score(true_class, predictions, average='micro')\n",
    "print (\"accuracy = \", accuracy)\n",
    "print()\n",
    "print(\"recall = \", recall)\n",
    "print()\n",
    "print(\"precision = \", precision)\n",
    "print()\n",
    "print(\"[[mask_weared_incorrect      -             -      ]\")\n",
    "print(\" [         -             with_mask         -      ]\")\n",
    "print(\" [         -                 -       without_mask ]]\")\n",
    "print()\n",
    "cm = confusion_matrix(true_class, predictions)\n",
    "print (cm)\n",
    "\n",
    "showconfusionmatrix(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72d1e53f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trying loading the pipeline.config...\t[LOADED]\n",
      "\n",
      "Trying restoring the checkpoint...\t[RESTORED]\n",
      "\n",
      "Trying loading the label_map...\t[LOADED]\n",
      "\n",
      "accuracy =  0.9192546583850931\n",
      "\n",
      "recall =  0.9192546583850931\n",
      "\n",
      "precision =  0.9192546583850931\n",
      "\n",
      "[[mask_weared_incorrect      -             -      ]\n",
      " [         -             with_mask         -      ]\n",
      " [         -                 -       without_mask ]]\n",
      "\n",
      "[[64  7  0]\n",
      " [ 4 35  1]\n",
      " [ 0  1 49]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'    # Suppress TensorFlow logging\n",
    "\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # Suppress Matplotlib warnings\n",
    "\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')           # Suppress TensorFlow logging (2)\n",
    "\n",
    "CUSTOM_MODEL_NAME = 'my_ssd_mobilnet'\n",
    "LABEL_MAP_NAME = 'label_map.pbtxt'\n",
    "\n",
    "paths = {\n",
    "    'ANNOTATION_PATH': os.path.join('Tensorflow', 'workspace','annotations'),\n",
    "    'CHECKPOINT_PATH': os.path.join('Tensorflow', 'workspace','exported-models', 'my_model', 'checkpoint')\n",
    " }\n",
    "\n",
    "files = {\n",
    "    'PIPELINE_CONFIG':os.path.join('Tensorflow', 'workspace','models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
    "    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n",
    "    }\n",
    "\n",
    "print()\n",
    "# %%\n",
    "# Load pipeline config and build a detection model\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "print(\"Trying loading the pipeline.config...\", end='\\t')\n",
    "configs = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\n",
    "model_config = configs['model']\n",
    "detection_model = model_builder.build(model_config=model_config, is_training=False)\n",
    "print(\"[LOADED]\")\n",
    "print()\n",
    "\n",
    "# %%\n",
    "# Restore checkpoint\n",
    "# ~~~~~~~~~~~~~~~~~~~~\n",
    "print(\"Trying restoring the checkpoint...\", end='\\t')\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(os.path.join(paths['CHECKPOINT_PATH'], 'ckpt-0')).expect_partial()\n",
    "print(\"[RESTORED]\")\n",
    "print()\n",
    "\n",
    "@tf.function\n",
    "def detect_fn(image):\n",
    "    \"\"\"Detect objects in image.\"\"\"\n",
    "\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "\n",
    "    return detections\n",
    "\n",
    "\n",
    "# %%\n",
    "# Load label map data (for plotting)\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "print(\"Trying loading the label_map...\", end='\\t')\n",
    "category_index = label_map_util.create_category_index_from_labelmap(files['LABELMAP'], use_display_name=True)\n",
    "print(\"[LOADED]\")\n",
    "print()\n",
    "\n",
    "\n",
    "def load_image_into_numpy_array(path):\n",
    "    return np.array(Image.open(path))\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for image_path in image_paths:\n",
    "    \n",
    "    image_np = load_image_into_numpy_array(image_path)\n",
    "\n",
    "    # Things to try:\n",
    "    # Flip horizontally\n",
    "    # image_np = np.fliplr(image_np).copy()\n",
    "\n",
    "    # Convert image to grayscale\n",
    "    # image_np = np.tile(\n",
    "    #     np.mean(image_np, 2, keepdims=True), (1, 1, 3)).astype(np.uint8)\n",
    "\n",
    "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "    \n",
    "    detections = detect_fn(input_tensor)\n",
    "    \n",
    "    if (not detections):\n",
    "        predictions.appen(\"nothing detected\")\n",
    "\n",
    "    # All outputs are batches tensors.\n",
    "    # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
    "    # We're only interested in the first num_detections.\n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy()\n",
    "                  for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "\n",
    "    # detection_classes should be ints.\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "    label_id_offset = 1\n",
    "    \n",
    "    boxes = detections['detection_boxes']\n",
    "    # get all boxes from an array\n",
    "    max_boxes_to_draw = boxes.shape[0]\n",
    "    # get scores to get a threshold\n",
    "    scores = detections['detection_scores']\n",
    "    # this is set as a default but feel free to adjust it to your needs\n",
    "    min_score_thresh = 0\n",
    "    \n",
    "    # # iterate over all objects found\n",
    "    for i in range(min(max_boxes_to_draw, boxes.shape[0])):\n",
    "        if scores[i] > min_score_thresh:\n",
    "            min_score_thresh = scores[i]\n",
    "            class_id = int(detections['detection_classes'][i] + label_id_offset)\n",
    "            \n",
    "    predictions.append(category_index[class_id][\"name\"])\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(true_class, predictions)\n",
    "recall = recall_score(true_class, predictions, average='micro')\n",
    "precision = precision_score(true_class, predictions, average='micro')\n",
    "print (\"accuracy = \", accuracy)\n",
    "print()\n",
    "print(\"recall = \", recall)\n",
    "print()\n",
    "print(\"precision = \", precision)\n",
    "print()\n",
    "print(\"[[mask_weared_incorrect      -             -      ]\")\n",
    "print(\" [         -             with_mask         -      ]\")\n",
    "print(\" [         -                 -       without_mask ]]\")\n",
    "print()\n",
    "cm = confusion_matrix(true_class, predictions)\n",
    "print (cm)\n",
    "\n",
    "showconfusionmatrix(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8639e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
