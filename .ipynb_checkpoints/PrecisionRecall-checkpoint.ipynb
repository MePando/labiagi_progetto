{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfaa505b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask_weared_incorrect 0\n",
      "with_mask 1\n",
      "without_mask 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0] global /tmp/pip-req-build-xw6jtoah/opencv_contrib/modules/xfeatures2d/misc/python/shadow_sift.hpp (13) SIFT_create DEPRECATED: cv.xfeatures2d.SIFT_create() is deprecated due SIFT tranfer to the main repository. https://github.com/opencv/opencv/issues/16736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy =  0.43478260869565216\n",
      "\n",
      "recall =  0.43478260869565216\n",
      "\n",
      "precision =  0.43478260869565216\n",
      "\n",
      "[[mask_weared_incorrect      -             -      ]\n",
      " [         -             with_mask         -      ]\n",
      " [         -                 -       without_mask ]]\n",
      "\n",
      "[[54 17  0]\n",
      " [24 16  0]\n",
      " [15 35  0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD+CAYAAAAXiMgWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAASWElEQVR4nO3de5BfZX3H8feHXAxEBMLGNIZgqAaY6AxqU2q1rQjSBrQNf1glMkzaoWbaSkcHHY2Xab12sNMqjKWXpaAZtUHqpVBgjCmFYaiIBEQuiUhEGRIDMVzkIkKy++0f51n7yya75+zu87s9v89r5sz+zuX3nO+Z3e8+z3nOc85RRGBmZTqk2wGYWfs4wc0K5gQ3K5gT3KxgTnCzgjnBzQrmBM9E0qGS/kvSzyX9xwzKOUfSt3LG1i2SflfSfd2OY5Bp0K6DS3oHcAFwIvAUcCfwqYi4eYblngv8FfC6iNg30zh7naQAlkfE9m7HYhMbqBpc0gXARcDfAouAY4F/AlZnKP6lwA8HIbmbkDS72zEYEBEDMQFHAE8DfzzJNi+g+gfw0zRdBLwgrTsF2AG8F9gN7AL+NK37GPA8sDft4zzgo8CXWspeBgQwO83/CfAAVSvix8A5Lctvbvne64DbgJ+nn69rWXcj8Angf1M53wKGJji2sfjf3xL/WcCZwA+Bx4APtWx/MnAL8ETa9h+BuWndTelYnknH+/aW8j8APAx8cWxZ+s7L0j5ek+ZfAvwMOKXbfxslT10PoGMHCquAfWMJNsE2Hwe+A7wYWAh8G/hEWndK+v7HgTkpMX4BHJXWj0/oCRMcmA88CZyQ1i0GXpE+/yrBgQXA48C56Xtr0vzRaf2NwI+A44FD0/yFExzbWPx/neJ/Z0qwfwcOB14BPAscl7b/DeC1ab/LgG3Ae1rKC+DlByn/01T/KA9tTfC0zTuBrcBhwCbg77v9d1H6NEhN9KOBPTF5E/oc4OMRsTsifkZVM5/bsn5vWr83Iq6jqr1OmGY8o8ArJR0aEbsi4t6DbPNm4P6I+GJE7IuIjcAPgD9s2ebzEfHDiHgWuBJ41ST73EvV37AXuAIYAi6OiKfS/rcCJwFExO0R8Z20358A/wq8ocEx/U1EPJfi2U9EXApsB26l+qf24ZrybIYGKcEfBYZqzg1fAjzYMv9gWvarMsb9g/gF8MKpBhIRz1A1a/8c2CXpWkknNohnLKYlLfMPTyGeRyNiJH0eS8BHWtY/O/Z9ScdLukbSw5KepOq3GJqkbICfRcQva7a5FHgl8LmIeK5mW5uhQUrwW4DnqM47J/JTqs6yMcemZdPxDFVTdMyvta6MiE0RcTpVTfYDqj/8unjGYto5zZim4p+p4loeES8CPgSo5juTXpKR9EKqfo3LgI9KWpAhTpvEwCR4RPyc6vzzEklnSTpM0hxJZ0j6u7TZRuAjkhZKGkrbf2mau7wT+D1Jx0o6Avjg2ApJiyStljSf6p/O01TN2/GuA46X9A5JsyW9HVgBXDPNmKbicKp+gqdT6+Ivxq1/BPj1KZZ5MbAlIv4MuBb4lxlHaZMamAQHiIh/oLoG/hGqDqaHgPOB/0ybfBLYAtwF3A3ckZZNZ1+bga+ksm5n/6Q8JMXxU6qe5TdwYAIREY8Cb6HquX+Uqgf8LRGxZzoxTdH7gHdQ9c5fSnUsrT4KbJD0hKS31RUmaTVVR+fYcV4AvEbSOdkitgMM3EAXs0HiwQhmGfzBGw+LPY8d7CzrQHfc9dymiFjV5pAAJ7hZFnseG+Hb31xSvyEw7yU/rrsakY0T3CyDAEYnv4jQFU5ws0xGD3ohpLuc4GYZBMFID3ZYF3GZTNIqSfdJ2i5pfbfjaSdJl0vaLemebsfSbpKWSrpB0lZJ90p6d7djmswo0WjqpL5PcEmzgEuAM6gGgayRtKK7UbXVF6iuJw+CfcB7I2IF1Y0v7+rV320AI0SjqZNKaKKfDGyPiAcAJF1BdX/31q5G1SYRcZOkZd2OoxMiYhfVrapExFOStlGNw++5320Ae6P3zsH7vgan+oU/1DK/g/1vxrACpH9qr6a6E60njTacOqmEGtwKl25S+RrV/ehPdjueg4kuNL+bKCHBdwJLW+aPoTN3W1kHSJpDldxfjoivdzueCQWM9F5+F9FEvw1YLuk4SXOBs4GruxyTZSBJVLeWbouIz3Q7nslUA116r4ne9wmeHsBwPtUjgLYBV07wdJQiSNpIdW/7CZJ2SDqv2zG10eupnqhzqqQ703Rmt4M6ODHScGpUmvQTSXenY96Sli2QtFnS/ennUXXllNBEJz0+6bpux9EJEbGm2zF0SlSPsm6WEV0WwGj+Jvobx90avB64PiIuTOM91lM95HJCfV+Dm/WCAJ7nkEbTDKwGNqTPG5j86USAE9wsm9FQo6mhAL4l6XZJ69KyRWlsAFTP4ltUV0gRTXSzbqtGsjVO3qGx8+pkOCKGx23zOxGxU9KLgc2SfrDf/iIivV1mUk5wswwCMdK8QbwnIlZOWl7EzvRzt6RvUI3YfETS4ojYJWkx1QssJuUmulkmuZrokuZLOnzsM/D7wD1Ul3/Xps3WAlfVlVVMgrecpwyEQTrefjjWsSZ6pstki4CbJX0f+C5wbUR8E7gQOF3S/cCb0vykSmqirwPGn8eUbJCOtw+OVYxEnvoy3Th10kGWPwqcNpWySkpws64JYC+zuh3GAdqS4EMLZsWypXPaUfSEjl0ym5UnzevKaOBtOxd2fJ9z5x/F/KGlHT/eWY8+0+ldMo/DeJEWdPxYf8kzPB/PNWpTR+SrwXNqS4IvWzqH725aWr9hIX7zwwe8s6BYCz5/S7dD6Jhb4/opbT/ag4Pu3EQ3y6DqZBuQGtxs8AxQE91s0FS3izrBzYo10nycecc4wc0yCMTe6L106r2IzPqQO9nMChbITXSzkrmTzaxQEfgymVm55JFsZqUK4Hn3opuVKZjS89Y6xglulokvk5kVqnouuhPcrFDN31rSSU5wswxcg5sVzjW4WaEixN7R3kun3ovIrA9V94O7BjcrlJ/oYlasqpPNNbhZsTzQxaxQHqpqVrhevB+8UUSSVkm6T9J2SevbHZRZv4mAvaOHNJo6qbYGlzQLuAQ4HdgB3Cbp6ojY2u7gzPpF1UTvzxr8ZGB7RDwQEc8DVwCr2xuWWf/J+PrgbJqcgy8BHmqZ3wH8VnvCMetPxV8mSy9pXwfVmz7NBkv/NtF3Aq2vCj0mLdtPRAxHxMqIWLnw6N57T7JZu42m57LVTZ3UJMFvA5ZLOk7SXOBs4Or2hmXWX6qnqqrR1JSkWZK+J+maNH+cpFvT1ayvpHycVG2CR8Q+4HxgE7ANuDIi7m0cpdkACMS+0VmNpil4N1XOjfk08NmIeDnwOHBeXQGNThoi4rqIOD4iXhYRn5pKhGaDImcTXdIxwJuBf0vzAk4Fvpo22QCcVVeOe8PMMphiL/qQpC0t88MRMTxum4uA9wOHp/mjgSdSixqqq1lL6nbkBDfLZAq96HsiYuVEKyW9BdgdEbdLOmUmMTnBzXKIrDebvB74I0lnAvOAFwEXA0dKmp1q8YNezRqv9y7cmfWhsSe65DgHj4gPRsQxEbGM6qrV/0TEOcANwFvTZmuBq+rKcoKbZTKaavG6aQY+AFwgaTvVOflldV9wE90sgwD2teFOsYi4EbgxfX6A6t6QxpzgZhn4gQ9mhfNTVc1KFYXfTWY2yIq/XdRs0DnBzQoViJEOP2+tCSe4WSbuZDMrVLiTzaxs4QQ3K5UHupgVzTW4WaF8HdysZOmhi73GCW6WQeAmulnB3MlmVrSIbkdwICe4WSZuopsVKmKAEvyePQs58dK/bEfRPenIvaPdDsF6gM/BzQo2OuoENytSoMFpopsNoh7sRHeCm2UxSJ1sZgOpB6twJ7hZJq7BzQrmkWxmhYqA8EMXzcrlGtysZE5ws1J5oItZ2VyDmxWqRwe69F63n1m/ioZTDUnzJH1X0vcl3SvpY2n5cZJulbRd0lckza0rywlulkuo2VTvOeDUiDgJeBWwStJrgU8Dn42IlwOPA+fVFeQEN8slUw0elafT7Jw0BXAq8NW0fANwVl1ZTnCzHIKcNTiSZkm6E9gNbAZ+BDwREfvSJjuAJXXluJPNLJMpDHQZkrSlZX44Iob3LytGgFdJOhL4BnDidGJygpvl0jzB90TEykZFRjwh6Qbgt4EjJc1OtfgxwM6677uJbpZLpia6pIWp5kbSocDpwDbgBuCtabO1wFV1ZbkGN8shQPmevbkY2CBpFlUlfGVEXCNpK3CFpE8C3wMuqyvICW6WRfMOtDoRcRfw6oMsfwA4eSplOcHNcvFQVbOCOcHNCtaDCV7biy7pckm7Jd3TiYDM+lLmgS65NLlM9gVgVZvjMOt7imZTJ9UmeETcBDzWgVjM+lumseg5+RzcLJNO185NZEtwSeuAdQCzjzgqV7Fm/aPkBz5ExHBErIyIlbPmz89VrFl/aNo8dxPdrE/1YBO9yWWyjcAtwAmSdkiqfYqE2SDqxV702ho8ItZ0IhCzvteDNbib6GYZKO/dZNk4wc1y6cFedCe4WS5uopuVq+iBLmYDzwluVqguXAJrwglulosT3KxcvXiZzI9NNiuYa3CzXNxENyuUO9nMCucENyuYE9ysTMJNdLNy+W4ys8K5BjcrmBPcrFw+BzcrmRPcrFBdeCRyEx6LbpaJRptNteVISyXdIGmrpHslvTstXyBps6T708/aN4w4wc0yyfjY5H3AeyNiBfBa4F2SVgDrgesjYjlwfZqflBPcLJdMbzaJiF0RcUf6/BSwDVgCrAY2pM02AGfVleVzcLMc2nQOLmkZ8GrgVmBRROxKqx4GFtV9vy0JPvuXsGBbDw7raZNn1zzR7RA650vdDqA3KU0NDUna0jI/HBHDB5QpvRD4GvCeiHhS+v89RERI9Q1+1+BmuTSvwfdExMrJNpA0hyq5vxwRX0+LH5G0OCJ2SVoM7K7bkc/BzTLJ1cmmqqq+DNgWEZ9pWXU1sDZ9XgtcVVeWa3CzXPKdlb4eOBe4W9KdadmHgAuBK9MLQB8E3lZXkBPcLIeMT3SJiJuZ+JT+tKmU5QQ3y6UHR7I5wc0y8c0mZiVzgpuVyzW4Wal69G4yJ7hZBsLPZDMrm2tws3Ipei/DneBmOfgc3Kxs7kU3K5kT3KxcrsHNSuVXF5kVzjW4WZn8dlGz0vk6uFm5XIOblcoDXczK5l50s4I5wc1KFbiTzaxkvdjJVvvig4leZWpm42R6+WBOTWrwsVeZ3iHpcOB2SZsjYmubYzPrG3070CW9zXBX+vyUpLFXmTrBzcZE9P85+LhXmZpZi77uRR//KtODrF8HrAOYe9hR2QI06xe92ERv9HbRCV5lup+IGI6IlRGxcs68+TljNOt9AYxGs6mDamvwSV5lamat+rQGH3uV6amS7kzTmW2Oy6zv5Ho/eE5NetEne5WpmY3p9150M5tYL3ayOcHNMlCAOtyB1kSjXnQza2C04dSApMsl7ZZ0T8uyBZI2S7o//ay9Hu0EN8tEEY2mhr4ArBq3bD1wfUQsB65P85Nygpvl0PRGk4b5HRE3AY+NW7wa2JA+bwDOqivH5+BmWUxpLPqQpC0t88MRMdzge4vSvSEADwOL6r7gBDfLZAq96HsiYuVM9hURIdXv0U10s1zG7iirm6bvEUmLAdLP3XVfcIKb5RCgkWg0zcDVwNr0eS1wVd0XnOBmuWTsZJO0EbgFOEHSDknnARcCp0u6H3hTmp+Uz8HNMpnCJbBaEbFmglWnTaUcJ7hZLh6LblaooPEotU5ygptlIKY0Sq1jnOBmuTjBzQoVwMwugbWFE9wsEzfRzUrmBDcrVQEvPjCzCfjtomaF83Vws3K5k82sVAGM9F4V7gQ3y2KAOtmeeWzHnls3vu/BdpQ9iSFgT4f3WdnYlb1273g7r1vH+tIpbT0oCR4RC9tR7mQkbZnpY3D6ySAdb98c66AkuNnAGXu7aI9xgptlERDuZGunJo+dLckgHW/vH6t70dur4XOlizFIx9s3x+pzcLOCOcHNSjVA18HNBk4Aoz4HNyuXa3CzgjnBzQoVQYyMdDuKAzjBzXLxSDazgrmJblaoCPeimxXNNbhZucI1uFmpPJLNrFwB9OBlskO6HYBZCQKI0Wg0NSFplaT7JG2XtH66cTnBzXKI9MCHJlMNSbOAS4AzgBXAGkkrphOWE9wsk4w1+MnA9oh4ICKeB64AVk8nJie4WS6ZanBgCfBQy/yOtGzK3MlmlsFTPL7pv+OrQw03nydpS8v8cLueWuMEN8sgIlZlLG4nsLRl/pi0bMrcRDfrPbcByyUdJ2kucDZw9XQKcg1u1mMiYp+k84FNwCzg8oi4dzplKXpw9I2Z5eEmulnBnOBmBXOCmxXMCW5WMCe4WcGc4GYFc4KbFcwJblaw/wP8GSYre3iAUQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pylab as pl\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score #sreeni\n",
    "import joblib\n",
    "\n",
    "\n",
    "# Load the classifier, class names, scaler, number of clusters and vocabulary \n",
    "#from stored pickle file (generated during training)\n",
    "clf, classes_names, stdSlr, k, voc = joblib.load(\"bovw.pkl\")\n",
    "\n",
    "# Get the path of the testing image(s) and store them in a list\n",
    "test_path = 'Tensorflow/workspace/images/test_bovw'\n",
    "\n",
    "testing_names = os.listdir(test_path)\n",
    "testing_names.sort() #['mask_weared_incorrect', 'with_mask', 'without_mask']\n",
    "\n",
    "# Get path to all images and save them in a list\n",
    "# image_paths and the corresponding label in image_paths\n",
    "image_paths = []\n",
    "image_classes = []\n",
    "class_id = 0\n",
    "\n",
    "#To make it easy to list all file names in a directory let us define a function\n",
    "#\n",
    "def imglist(path):\n",
    "    return [os.path.join(path, f) for f in os.listdir(path)]\n",
    "\n",
    "#Fill the placeholder empty lists with image path, classes, and add class ID number\n",
    "\n",
    "for testing_name in testing_names:\n",
    "    dir = os.path.join(test_path, testing_name)\n",
    "    image_list = imglist(dir)\n",
    "    image_paths+=image_list\n",
    "    image_classes+=[class_id]*len(image_list)\n",
    "    print(testing_name, end=\" \")\n",
    "    print(class_id)\n",
    "    class_id+=1\n",
    "    \n",
    "# Create feature extraction and keypoint detector objects\n",
    "# Create List where all the descriptors will be stored\n",
    "des_list = []\n",
    "\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "for image_path in image_paths:\n",
    "    im = cv2.imread(image_path)\n",
    "    kpts, des = sift.detectAndCompute(im, None)\n",
    "    des_list.append((image_path, des))   \n",
    "    \n",
    "# Stack all the descriptors vertically in a numpy array\n",
    "descriptors = des_list[0][1]\n",
    "for image_path, descriptor in des_list[0:]:\n",
    "    descriptors = np.vstack((descriptors, descriptor)) \n",
    "\n",
    "# Calculate the histogram of features\n",
    "#vq Assigns codes from a code book to observations.\n",
    "from scipy.cluster.vq import vq    \n",
    "test_features = np.zeros((len(image_paths), k), \"float32\")\n",
    "for i in range(len(image_paths)):\n",
    "    words, distance = vq(des_list[i][1],voc)\n",
    "    for w in words:\n",
    "        test_features[i][w] += 1\n",
    "\n",
    "# Perform Tf-Idf vectorization\n",
    "nbr_occurences = np.sum( (test_features > 0) * 1, axis = 0)\n",
    "idf = np.array(np.log((1.0*len(image_paths)+1) / (1.0*nbr_occurences + 1)), 'float32')\n",
    "\n",
    "# Scale the features\n",
    "#Standardize features by removing the mean and scaling to unit variance\n",
    "#Scaler (stdSlr comes from the pickled file we imported)\n",
    "test_features = stdSlr.transform(test_features)\n",
    "\n",
    "#######Until here most of the above code is similar to Train except for kmeans clustering####\n",
    "\n",
    "#Report true class names so they can be compared with predicted classes\n",
    "true_class =  [classes_names[i] for i in image_classes]\n",
    "# Perform the predictions and report predicted class names. \n",
    "predictions =  [classes_names[i] for i in clf.predict(test_features)]\n",
    "\n",
    "\n",
    "###############################################\n",
    "#To make it easy to understand the accuracy let us print the confusion matrix\n",
    "\n",
    "def showconfusionmatrix(cm):\n",
    "    pl.matshow(cm)\n",
    "    pl.title('Confusion matrix')\n",
    "    pl.colorbar()\n",
    "    pl.show()\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(true_class, predictions)\n",
    "recall = recall_score(true_class, predictions, average='micro')\n",
    "precision = precision_score(true_class, predictions, average='micro')\n",
    "print (\"accuracy = \", accuracy)\n",
    "print()\n",
    "print(\"recall = \", recall)\n",
    "print()\n",
    "print(\"precision = \", precision)\n",
    "print()\n",
    "print(\"[[mask_weared_incorrect      -             -      ]\")\n",
    "print(\" [         -             with_mask         -      ]\")\n",
    "print(\" [         -                 -       without_mask ]]\")\n",
    "print()\n",
    "cm = confusion_matrix(true_class, predictions)\n",
    "print (cm)\n",
    "\n",
    "showconfusionmatrix(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72d1e53f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trying loading the pipeline.config...\t[LOADED]\n",
      "\n",
      "Trying restoring the checkpoint...\t[RESTORED]\n",
      "\n",
      "Trying loading the label_map...\t[LOADED]\n",
      "\n",
      "accuracy =  0.9254658385093167\n",
      "\n",
      "recall =  0.9254658385093167\n",
      "\n",
      "precision =  0.9254658385093167\n",
      "\n",
      "[[mask_weared_incorrect      -             -      ]\n",
      " [         -             with_mask         -      ]\n",
      " [         -                 -       without_mask ]]\n",
      "\n",
      "[[64  7  0]\n",
      " [ 0 37  3]\n",
      " [ 1  1 48]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'    # Suppress TensorFlow logging\n",
    "\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # Suppress Matplotlib warnings\n",
    "\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')           # Suppress TensorFlow logging (2)\n",
    "\n",
    "CUSTOM_MODEL_NAME = 'my_ssd_mobilnet'\n",
    "LABEL_MAP_NAME = 'label_map.pbtxt'\n",
    "\n",
    "paths = {\n",
    "    'ANNOTATION_PATH': os.path.join('Tensorflow', 'workspace','annotations'),\n",
    "    'CHECKPOINT_PATH': os.path.join('Tensorflow', 'workspace','exported-models', 'my_model', 'checkpoint')\n",
    " }\n",
    "\n",
    "files = {\n",
    "    'PIPELINE_CONFIG':os.path.join('Tensorflow', 'workspace','models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
    "    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n",
    "    }\n",
    "\n",
    "print()\n",
    "# %%\n",
    "# Load pipeline config and build a detection model\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "print(\"Trying loading the pipeline.config...\", end='\\t')\n",
    "configs = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\n",
    "model_config = configs['model']\n",
    "detection_model = model_builder.build(model_config=model_config, is_training=False)\n",
    "print(\"[LOADED]\")\n",
    "print()\n",
    "\n",
    "# %%\n",
    "# Restore checkpoint\n",
    "# ~~~~~~~~~~~~~~~~~~~~\n",
    "print(\"Trying restoring the checkpoint...\", end='\\t')\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(os.path.join(paths['CHECKPOINT_PATH'], 'ckpt-0')).expect_partial()\n",
    "print(\"[RESTORED]\")\n",
    "print()\n",
    "\n",
    "@tf.function\n",
    "def detect_fn(image):\n",
    "    \"\"\"Detect objects in image.\"\"\"\n",
    "\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "\n",
    "    return detections\n",
    "\n",
    "\n",
    "# %%\n",
    "# Load label map data (for plotting)\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "print(\"Trying loading the label_map...\", end='\\t')\n",
    "category_index = label_map_util.create_category_index_from_labelmap(files['LABELMAP'], use_display_name=True)\n",
    "print(\"[LOADED]\")\n",
    "print()\n",
    "\n",
    "\n",
    "def load_image_into_numpy_array(path):\n",
    "    return np.array(Image.open(path))\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for image_path in image_paths:\n",
    "    \n",
    "    image_np = load_image_into_numpy_array(image_path)\n",
    "\n",
    "    # Things to try:\n",
    "    # Flip horizontally\n",
    "    # image_np = np.fliplr(image_np).copy()\n",
    "\n",
    "    # Convert image to grayscale\n",
    "    # image_np = np.tile(\n",
    "    #     np.mean(image_np, 2, keepdims=True), (1, 1, 3)).astype(np.uint8)\n",
    "\n",
    "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "    \n",
    "    detections = detect_fn(input_tensor)\n",
    "\n",
    "    # All outputs are batches tensors.\n",
    "    # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
    "    # We're only interested in the first num_detections.\n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy()\n",
    "                  for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "\n",
    "    # detection_classes should be ints.\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "    label_id_offset = 1\n",
    "    \n",
    "    #return the class with the most probability\n",
    "    class_id = int(detections['detection_classes'][0] + label_id_offset)\n",
    "            \n",
    "    predictions.append(category_index[class_id][\"name\"])\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(true_class, predictions)\n",
    "recall = recall_score(true_class, predictions, average='micro')\n",
    "precision = precision_score(true_class, predictions, average='micro')\n",
    "print (\"accuracy = \", accuracy)\n",
    "print()\n",
    "print(\"recall = \", recall)\n",
    "print()\n",
    "print(\"precision = \", precision)\n",
    "print()\n",
    "print(\"[[mask_weared_incorrect      -             -      ]\")\n",
    "print(\" [         -             with_mask         -      ]\")\n",
    "print(\" [         -                 -       without_mask ]]\")\n",
    "print()\n",
    "cm = confusion_matrix(true_class, predictions)\n",
    "print (cm)\n",
    "\n",
    "showconfusionmatrix(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f6be53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
